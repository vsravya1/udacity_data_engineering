{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sql_queries import create_table_queries, drop_table_queries\n",
    "\n",
    "\n",
    "def create_database():\n",
    "    \"\"\"\n",
    "    - Creates and connects to the sparkifydb\n",
    "    - Returns the connection and cursor to sparkifydb\n",
    "    \"\"\"\n",
    "    \n",
    "    # connect to default database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # create sparkify database with UTF8 encoding\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS sparkifydb\")\n",
    "    cur.execute(\"CREATE DATABASE sparkifydb WITH ENCODING 'utf8' TEMPLATE template0\")\n",
    "\n",
    "    # close connection to default database\n",
    "    conn.close()    \n",
    "    \n",
    "    # connect to sparkify database\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    return cur, conn\n",
    "\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Drops each table using the queries in `drop_table_queries` list.\n",
    "    \"\"\"\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Creates each table using the queries in `create_table_queries` list. \n",
    "    \"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    - Drops (if exists) and Creates the sparkify database. \n",
    "    \n",
    "    - Establishes connection with the sparkify database and gets\n",
    "    cursor to it.  \n",
    "    \n",
    "    - Drops all the tables.  \n",
    "    \n",
    "    - Creates all tables needed. \n",
    "    \n",
    "    - Finally, closes the connection. \n",
    "    \"\"\"\n",
    "    cur, conn = create_database()\n",
    "    \n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 files found in data/song_data\n",
      "1/75 files processed.\n",
      "2/75 files processed.\n",
      "3/75 files processed.\n",
      "4/75 files processed.\n",
      "5/75 files processed.\n",
      "6/75 files processed.\n",
      "7/75 files processed.\n",
      "8/75 files processed.\n",
      "9/75 files processed.\n",
      "10/75 files processed.\n",
      "11/75 files processed.\n",
      "12/75 files processed.\n",
      "13/75 files processed.\n",
      "14/75 files processed.\n",
      "15/75 files processed.\n",
      "16/75 files processed.\n",
      "17/75 files processed.\n",
      "18/75 files processed.\n",
      "19/75 files processed.\n",
      "20/75 files processed.\n",
      "21/75 files processed.\n",
      "22/75 files processed.\n",
      "23/75 files processed.\n",
      "24/75 files processed.\n",
      "25/75 files processed.\n",
      "26/75 files processed.\n",
      "27/75 files processed.\n",
      "28/75 files processed.\n",
      "29/75 files processed.\n",
      "30/75 files processed.\n",
      "31/75 files processed.\n",
      "32/75 files processed.\n",
      "33/75 files processed.\n",
      "34/75 files processed.\n",
      "35/75 files processed.\n",
      "36/75 files processed.\n",
      "37/75 files processed.\n",
      "38/75 files processed.\n",
      "39/75 files processed.\n",
      "40/75 files processed.\n",
      "41/75 files processed.\n",
      "42/75 files processed.\n",
      "43/75 files processed.\n",
      "44/75 files processed.\n",
      "45/75 files processed.\n",
      "46/75 files processed.\n",
      "47/75 files processed.\n",
      "48/75 files processed.\n",
      "49/75 files processed.\n",
      "50/75 files processed.\n",
      "51/75 files processed.\n",
      "52/75 files processed.\n",
      "53/75 files processed.\n",
      "54/75 files processed.\n",
      "55/75 files processed.\n",
      "56/75 files processed.\n",
      "57/75 files processed.\n",
      "58/75 files processed.\n",
      "59/75 files processed.\n",
      "60/75 files processed.\n",
      "61/75 files processed.\n",
      "62/75 files processed.\n",
      "63/75 files processed.\n",
      "64/75 files processed.\n",
      "65/75 files processed.\n",
      "66/75 files processed.\n",
      "67/75 files processed.\n",
      "68/75 files processed.\n",
      "69/75 files processed.\n",
      "70/75 files processed.\n",
      "71/75 files processed.\n",
      "72/75 files processed.\n",
      "73/75 files processed.\n",
      "74/75 files processed.\n",
      "75/75 files processed.\n",
      "31 files found in data/log_data\n",
      "1/31 files processed.\n",
      "2/31 files processed.\n",
      "3/31 files processed.\n",
      "4/31 files processed.\n",
      "5/31 files processed.\n",
      "6/31 files processed.\n",
      "7/31 files processed.\n",
      "8/31 files processed.\n",
      "9/31 files processed.\n",
      "10/31 files processed.\n",
      "11/31 files processed.\n",
      "12/31 files processed.\n",
      "13/31 files processed.\n",
      "14/31 files processed.\n",
      "15/31 files processed.\n",
      "16/31 files processed.\n",
      "17/31 files processed.\n",
      "18/31 files processed.\n",
      "19/31 files processed.\n",
      "20/31 files processed.\n",
      "21/31 files processed.\n",
      "22/31 files processed.\n",
      "23/31 files processed.\n",
      "24/31 files processed.\n",
      "25/31 files processed.\n",
      "26/31 files processed.\n",
      "27/31 files processed.\n",
      "28/31 files processed.\n",
      "29/31 files processed.\n",
      "30/31 files processed.\n",
      "31/31 files processed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sql_queries import *\n",
    "\n",
    "\n",
    "def process_song_file(cur, filepath):\n",
    "    # open song file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # insert song record\n",
    "    song_data = df[[\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\"]].values[0].tolist()\n",
    "    cur.execute(song_table_insert, song_data)\n",
    "    \n",
    "    # insert artist record\n",
    "    artist_data = df[[\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\"]].values[0].tolist()\n",
    "    cur.execute(artist_table_insert, artist_data)\n",
    "\n",
    "\n",
    "def process_log_file(cur, filepath):\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # filter by NextSong action\n",
    "    df = df[df['page'] == 'NextSong']\n",
    "\n",
    "    # convert timestamp column to datetime\n",
    "    t =  pd.to_datetime(df['ts'], unit='ms')\n",
    "    df['ts'] = pd.to_datetime(df['ts'], unit='ms')\n",
    "    \n",
    "    # insert time data records\n",
    "    time_data =  list((t, t.dt.hour, t.dt.day, t.dt.weekofyear, t.dt.month, t.dt.year, t.dt.weekday))\n",
    "    column_labels = list(('start_time', 'hour', 'day', 'week', 'month', 'year', 'weekday'))\n",
    "    time_df = pd.DataFrame.from_dict(dict(zip(column_labels, time_data)))\n",
    "\n",
    "    for i, row in time_df.iterrows():\n",
    "        cur.execute(time_table_insert, list(row))\n",
    "\n",
    "    # load user table\n",
    "    user_df = df[[\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\"]]\n",
    "\n",
    "    # insert user records\n",
    "    for i, row in user_df.iterrows():\n",
    "        cur.execute(user_table_insert, row)\n",
    "\n",
    "    # insert songplay records\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        # get songid and artistid from song and artist tables\n",
    "        cur.execute(song_select, (row.song, row.artist, row.length))\n",
    "        results = cur.fetchone()\n",
    "        \n",
    "        if results:\n",
    "            songid, artistid = results\n",
    "        else:\n",
    "            songid, artistid = None, None\n",
    "\n",
    "        # insert songplay record\n",
    "        songplay_data = (row.ts, row.userId, row.level, songid, artistid, row.sessionId,row.location, row.userAgent)\n",
    "        cur.execute(songplay_table_insert, songplay_data)\n",
    "\n",
    "\n",
    "def process_data(cur, conn, filepath, func):\n",
    "    # get all files matching extension from directory\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.json'))\n",
    "        for f in files :\n",
    "            all_files.append(os.path.abspath(f))\n",
    "\n",
    "    # get total number of files found\n",
    "    num_files = len(all_files)\n",
    "    print('{} files found in {}'.format(num_files, filepath))\n",
    "\n",
    "    # iterate over files and process\n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "        func(cur, datafile)\n",
    "        conn.commit()\n",
    "        print('{}/{} files processed.'.format(i, num_files))\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    process_data(cur, conn, filepath='data/song_data', func=process_song_file)\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
